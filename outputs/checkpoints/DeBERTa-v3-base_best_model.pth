Items: 202
000: model.embeddings.word_embeddings.weight                      (128100, 768)
001: model.embeddings.LayerNorm.weight                            (768,)
002: model.embeddings.LayerNorm.bias                              (768,)
003: model.encoder.layer.0.attention.self.query_proj.weight       (768, 768)
004: model.encoder.layer.0.attention.self.query_proj.bias         (768,)
005: model.encoder.layer.0.attention.self.key_proj.weight         (768, 768)
006: model.encoder.layer.0.attention.self.key_proj.bias           (768,)
007: model.encoder.layer.0.attention.self.value_proj.weight       (768, 768)
008: model.encoder.layer.0.attention.self.value_proj.bias         (768,)
009: model.encoder.layer.0.attention.output.dense.weight          (768, 768)
010: model.encoder.layer.0.attention.output.dense.bias            (768,)
011: model.encoder.layer.0.attention.output.LayerNorm.weight      (768,)
012: model.encoder.layer.0.attention.output.LayerNorm.bias        (768,)
013: model.encoder.layer.0.intermediate.dense.weight              (3072, 768)
014: model.encoder.layer.0.intermediate.dense.bias                (3072,)
015: model.encoder.layer.0.output.dense.weight                    (768, 3072)
016: model.encoder.layer.0.output.dense.bias                      (768,)
017: model.encoder.layer.0.output.LayerNorm.weight                (768,)
018: model.encoder.layer.0.output.LayerNorm.bias                  (768,)
019: model.encoder.layer.1.attention.self.query_proj.weight       (768, 768)
020: model.encoder.layer.1.attention.self.query_proj.bias         (768,)
021: model.encoder.layer.1.attention.self.key_proj.weight         (768, 768)
022: model.encoder.layer.1.attention.self.key_proj.bias           (768,)
023: model.encoder.layer.1.attention.self.value_proj.weight       (768, 768)
024: model.encoder.layer.1.attention.self.value_proj.bias         (768,)
025: model.encoder.layer.1.attention.output.dense.weight          (768, 768)
026: model.encoder.layer.1.attention.output.dense.bias            (768,)
027: model.encoder.layer.1.attention.output.LayerNorm.weight      (768,)
028: model.encoder.layer.1.attention.output.LayerNorm.bias        (768,)
029: model.encoder.layer.1.intermediate.dense.weight              (3072, 768)
030: model.encoder.layer.1.intermediate.dense.bias                (3072,)
031: model.encoder.layer.1.output.dense.weight                    (768, 3072)
032: model.encoder.layer.1.output.dense.bias                      (768,)
033: model.encoder.layer.1.output.LayerNorm.weight                (768,)
034: model.encoder.layer.1.output.LayerNorm.bias                  (768,)
035: model.encoder.layer.2.attention.self.query_proj.weight       (768, 768)
036: model.encoder.layer.2.attention.self.query_proj.bias         (768,)
037: model.encoder.layer.2.attention.self.key_proj.weight         (768, 768)
038: model.encoder.layer.2.attention.self.key_proj.bias           (768,)
039: model.encoder.layer.2.attention.self.value_proj.weight       (768, 768)
040: model.encoder.layer.2.attention.self.value_proj.bias         (768,)
041: model.encoder.layer.2.attention.output.dense.weight          (768, 768)
042: model.encoder.layer.2.attention.output.dense.bias            (768,)
043: model.encoder.layer.2.attention.output.LayerNorm.weight      (768,)
044: model.encoder.layer.2.attention.output.LayerNorm.bias        (768,)
045: model.encoder.layer.2.intermediate.dense.weight              (3072, 768)
046: model.encoder.layer.2.intermediate.dense.bias                (3072,)
047: model.encoder.layer.2.output.dense.weight                    (768, 3072)
048: model.encoder.layer.2.output.dense.bias                      (768,)
049: model.encoder.layer.2.output.LayerNorm.weight                (768,)
050: model.encoder.layer.2.output.LayerNorm.bias                  (768,)
