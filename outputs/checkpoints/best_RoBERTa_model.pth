Items: 203
000: model.embeddings.word_embeddings.weight                      (50265, 768)
001: model.embeddings.position_embeddings.weight                  (514, 768)
002: model.embeddings.token_type_embeddings.weight                (1, 768)
003: model.embeddings.LayerNorm.weight                            (768,)
004: model.embeddings.LayerNorm.bias                              (768,)
005: model.encoder.layer.0.attention.self.query.weight            (768, 768)
006: model.encoder.layer.0.attention.self.query.bias              (768,)
007: model.encoder.layer.0.attention.self.key.weight              (768, 768)
008: model.encoder.layer.0.attention.self.key.bias                (768,)
009: model.encoder.layer.0.attention.self.value.weight            (768, 768)
010: model.encoder.layer.0.attention.self.value.bias              (768,)
011: model.encoder.layer.0.attention.output.dense.weight          (768, 768)
012: model.encoder.layer.0.attention.output.dense.bias            (768,)
013: model.encoder.layer.0.attention.output.LayerNorm.weight      (768,)
014: model.encoder.layer.0.attention.output.LayerNorm.bias        (768,)
015: model.encoder.layer.0.intermediate.dense.weight              (3072, 768)
016: model.encoder.layer.0.intermediate.dense.bias                (3072,)
017: model.encoder.layer.0.output.dense.weight                    (768, 3072)
018: model.encoder.layer.0.output.dense.bias                      (768,)
019: model.encoder.layer.0.output.LayerNorm.weight                (768,)
020: model.encoder.layer.0.output.LayerNorm.bias                  (768,)
021: model.encoder.layer.1.attention.self.query.weight            (768, 768)
022: model.encoder.layer.1.attention.self.query.bias              (768,)
023: model.encoder.layer.1.attention.self.key.weight              (768, 768)
024: model.encoder.layer.1.attention.self.key.bias                (768,)
025: model.encoder.layer.1.attention.self.value.weight            (768, 768)
026: model.encoder.layer.1.attention.self.value.bias              (768,)
027: model.encoder.layer.1.attention.output.dense.weight          (768, 768)
028: model.encoder.layer.1.attention.output.dense.bias            (768,)
029: model.encoder.layer.1.attention.output.LayerNorm.weight      (768,)
030: model.encoder.layer.1.attention.output.LayerNorm.bias        (768,)
031: model.encoder.layer.1.intermediate.dense.weight              (3072, 768)
032: model.encoder.layer.1.intermediate.dense.bias                (3072,)
033: model.encoder.layer.1.output.dense.weight                    (768, 3072)
034: model.encoder.layer.1.output.dense.bias                      (768,)
035: model.encoder.layer.1.output.LayerNorm.weight                (768,)
036: model.encoder.layer.1.output.LayerNorm.bias                  (768,)
037: model.encoder.layer.2.attention.self.query.weight            (768, 768)
038: model.encoder.layer.2.attention.self.query.bias              (768,)
039: model.encoder.layer.2.attention.self.key.weight              (768, 768)
040: model.encoder.layer.2.attention.self.key.bias                (768,)
041: model.encoder.layer.2.attention.self.value.weight            (768, 768)
042: model.encoder.layer.2.attention.self.value.bias              (768,)
043: model.encoder.layer.2.attention.output.dense.weight          (768, 768)
044: model.encoder.layer.2.attention.output.dense.bias            (768,)
045: model.encoder.layer.2.attention.output.LayerNorm.weight      (768,)
046: model.encoder.layer.2.attention.output.LayerNorm.bias        (768,)
047: model.encoder.layer.2.intermediate.dense.weight              (3072, 768)
048: model.encoder.layer.2.intermediate.dense.bias                (3072,)
049: model.encoder.layer.2.output.dense.weight                    (768, 3072)
050: model.encoder.layer.2.output.dense.bias                      (768,)
